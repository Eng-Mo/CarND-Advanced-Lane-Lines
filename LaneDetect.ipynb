{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpimg\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "import os, sys\n",
    "import glob\n",
    "import moviepy\n",
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.editor import * \n",
    "from IPython import display\n",
    "from IPython.core.display import display\n",
    "from IPython.display import Image\n",
    "import pylab\n",
    "import scipy.misc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def region_of_interest(img):\n",
    "    mask = np.zeros(img.shape, dtype=np.uint8) #mask image\n",
    "    roi_corners = np.array([[(200,675), (1200,675), (700,430),(500,430)]], \n",
    "                           dtype=np.int32) # vertisies seted to form trapezoidal scene\n",
    "    channel_count = 1#img.shape[2]  # image channels\n",
    "    ignore_mask_color = (255,)*channel_count\n",
    "    cv2.fillPoly(mask, roi_corners, ignore_mask_color)   \n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    " \n",
    "    return masked_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CTHR(img):               # Threshold Yellow anf White Colos from RGB, HSV, HLS color spaces\n",
    "    \n",
    "    HSV = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # For yellow\n",
    "    yellow = cv2.inRange(HSV, (20, 100, 100), (50, 255, 255))\n",
    "\n",
    "    # For white\n",
    "    sensitivity_1 = 68\n",
    "    white = cv2.inRange(HSV, (0,0,255-sensitivity_1), (255,20,255))\n",
    "\n",
    "    sensitivity_2 = 60\n",
    "    HSL = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    white_2 = cv2.inRange(HSL, (0,255-sensitivity_2,0), (255,255,sensitivity_2))\n",
    "    white_3 = cv2.inRange(img, (200,200,200), (255,255,255))\n",
    "\n",
    "    bit_layer = yellow | white | white_2 | white_3\n",
    "    \n",
    "    return  bit_layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "\n",
    "def SobelThr(img):                     # Sobel edge detection extraction\n",
    "    gray=img\n",
    "    \n",
    "    \n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0,ksize=15)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1,ksize=15)\n",
    "    \n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    scaled_sobelx = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    scaled_sobely = np.uint8(255*abs_sobely/np.max(abs_sobely))\n",
    "   \n",
    "    \n",
    "    binary_outputabsx = np.zeros_like(scaled_sobelx)\n",
    "    binary_outputabsx[(scaled_sobelx >= 20) & (scaled_sobelx <= 255)] = 1\n",
    "   \n",
    "    \n",
    "    \n",
    "    binary_outputabsy = np.zeros_like(scaled_sobely)\n",
    "    binary_outputabsy[(scaled_sobely >= 100) & (scaled_sobely <= 150)] = 1\n",
    "\n",
    "    \n",
    "    mag_thresh=(100, 200)\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "   \n",
    "\n",
    "    scale_factor = np.max(gradmag)/255\n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    binary_outputmag = np.zeros_like(gradmag)\n",
    "    binary_outputmag[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "    combinedS = np.zeros_like(binary_outputabsx)\n",
    "    combinedS[(((binary_outputabsx == 1) | (binary_outputabsy == 1))|(binary_outputmag==1)) ] = 1\n",
    "   \n",
    "    return combinedS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combinI(b1,b2):     ##Combine color threshold + Sobel edge detection\n",
    "\n",
    "    combined = np.zeros_like(b1)\n",
    "    combined[((b1 == 1)|(b2 == 255)) ] = 1\n",
    "\n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prespectI(img):               # Calculate the prespective transform and warp the Image to the eye bird view\n",
    "    \n",
    " \n",
    "\n",
    "    src=np.float32([[728,475],\n",
    "                  [1058,690],\n",
    "                  [242,690],\n",
    "                  [565,475]])\n",
    "    \n",
    "    dst=np.float32([[1058,20],\n",
    "                  [1058,700],\n",
    "                  [242,700],\n",
    "                  [242,20]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(img, M, (1280,720), flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return (warped, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def undistorT(imgorg):              # Calculate Undistortion coefficients\n",
    "\n",
    "\n",
    "    nx =9\n",
    "    ny = 6\n",
    "    objpoints = []\n",
    "    imgpoints = []\n",
    "    objp=np.zeros((6*9,3),np.float32)\n",
    "    objp[:,:2]=np.mgrid[0:6,0:9].T.reshape(-1,2)\n",
    "\n",
    "\n",
    "    images=glob.glob('./camera_cal/calibration*.jpg')\n",
    "    for fname in images:                 # find corner points and Make a list of calibration images\n",
    "            img = cv2.imread(fname)\n",
    "            # Convert to grayscale\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            # Find the chessboard corners\n",
    "            ret, corners = cv2.findChessboardCorners(gray, (6,9),None)\n",
    "\n",
    "            # If found, draw corners\n",
    "            if ret == True:\n",
    "                imgpoints.append(corners)\n",
    "                objpoints.append(objp)\n",
    "                # Draw and display the corners\n",
    "                #cv2.drawChessboardCorners(img, (nx, ny), corners, ret)    \n",
    "\n",
    "\n",
    "    return cv2.calibrateCamera(objpoints,imgpoints,gray.shape[::-1],None,None)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def undistresult(img, mtx,dist):     #    undistort frame\n",
    "    undist= cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    \n",
    "    return undist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LineFitting(wimgun):                  #Fit Lane Lines\n",
    "\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 20\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "        \n",
    "\n",
    "    histogram = np.sum(wimgun[350:,:], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((wimgun, wimgun, wimgun))\n",
    "\n",
    "\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    nwindows = 9\n",
    "\n",
    "    # Set height of windows\n",
    "    window_height = np.int(wimgun.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = wimgun.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin =80\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = wimgun.shape[0] - (window+1)*window_height\n",
    "        win_y_high = wimgun.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, wimgun.shape[0]-1, wimgun.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "#     out_img = np.dstack((wimgun, wimgun, wimgun))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    \n",
    "    \n",
    "#     plt.plot(left_fitx, ploty, color='yellow')\n",
    "#     plt.plot(right_fitx, ploty, color='yellow')\n",
    "#     plt.xlim(0, 1280)\n",
    "#     plt.ylim(720, 0)\n",
    "#     plt.imshow(out_img)\n",
    "# #     plt.savefig(\"./output_images/Window Image\"+str(n)+\".png\")\n",
    "#     plt.show()\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "#     plt.title(\"r\")\n",
    "\n",
    "#     plt.plot(left_fitx, ploty, color='yellow')\n",
    "#     plt.plot(right_fitx, ploty, color='yellow')\n",
    "#     plt.xlim(0, 1280)\n",
    "#     plt.ylim(720, 0)\n",
    "#     plt.imshow(result)\n",
    "# #     plt.savefig(\"./output_images/Line Image\"+str(n)+\".png\")\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "    # Define y-value where we want radius of curvature\n",
    "    # I'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "    #print(left_curverad, right_curverad)\n",
    "    \n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "# Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "#     y_eval = np.max(ploty)\n",
    "\n",
    "# # Calculate the new radias of curvature\n",
    "   \n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "#    # left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "#    # right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "    \n",
    "    \n",
    "#     camera_center=wimgun.shape[0]/2\n",
    "#     #lane_center = (right_fitx[719] + left_fitx[719])/2    \n",
    "    lane_offset = (1280/2 - (left_fitx[-1]+right_fitx[-1])/2)*xm_per_pix\n",
    "#     print(left_curverad1, right_curverad1, lane_offset)\n",
    "\n",
    "    return (left_fit, ploty,right_fit,left_curverad, right_curverad,lane_offset)\n",
    "\n",
    "   \n",
    "\n",
    " # Create an image to draw the lines on\n",
    "def unwrappedframe(img,pm, Minv, left_fit,ploty,right_fit):\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    \n",
    "    warp_zero = np.zeros_like(pm).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0])) \n",
    "    \n",
    "    # Combine the result with the original image\n",
    "\n",
    "    return cv2.addWeighted(img, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
