{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%writefile README.md\n",
    "## Advanced Lane Detection Report\n",
    "---\n",
    "This project aims to detect Lane lines robustly during high lighting distortion. This report reprsents software pipline and preview two diffrent frames oitput at each stage. the first frame with normal lighting condition and second frame with high lighting disruption.\n",
    "\n",
    "### Project files\n",
    "1. `LaneDetect.py` contains all required functions for Lane detections.\n",
    "2. `Advanced-Lane-Detection.ipynb` contanis the software python code pipeline.\n",
    "---\n",
    "[image1]: ./output_images/test1_r.png \"distorted1\"\n",
    "[image2]: ./output_images/Undistored_test1_r.png \"Udistorted1\"\n",
    "[image3]: ./output_images/test1.png \"ROI\"\n",
    "[image4]: ./output_images/sobelTH-test1.png \n",
    "[image5]: ./output_images/colotTH-test1.png \n",
    "[image6]: ./output_images/combinedTH-test1.png\n",
    "[image7]: ./output_images/roi-test1.png\n",
    "[image8]: ./output_images/wraped-test1.png\n",
    "[image9]: ./output_images/window-test1.png\n",
    "[image10]: ./output_images/Lines-test1.png\n",
    "[image11]: ./output_images/Lane-test1.png\n",
    "[image12]: ./output_images/result.jpg\n",
    "\n",
    "\n",
    "\n",
    "#### 1. Camera calibration.\n",
    "\n",
    "The code for this step is contained in `def undistorT(imgorg)` function. I start by preparing \"object points\", which will be the (x, y, z) coordinates of the chessboard corners in the world. Here I am assuming the chessboard is fixed on the (x, y) plane at z=0, such that the object points are the same for each calibration image.  Thus, `objp` is just a replicated array of coordinates, and `objpoints` will be appended with a copy of it every time I successfully detect all chessboard corners in a test image.  `imgpoints` will be appended with the (x, y) pixel position of each of the corners in the image plane with each successful chessboard detection. I then used the output `objpoints` and `imgpoints` to compute the camera calibration and distortion coefficients using the `cv2.calibrateCamera()` function.  I applied this distortion correction to the test image using the `cv2.undistort()` function and obtained this result: \n",
    "\n",
    "![title][image1]\n",
    "![title][image2]\n",
    "#### 2. Image segmentation.\n",
    "I used a combination of color and gradient thresholds to generate a binary image. I made thrshold in two levels:\n",
    "\n",
    "1. I computed the gradiant of gray image of the frame in respective x & y. Also, graduate magnitude was calculated and minimum threshold was applied as in the function `SobelThr(img,n)`. The ouput binary Image segmented the Lane clearly in good lighting condition but with some noise in distorted frame with high lightness.\n",
    "![title][image3]\n",
    "\n",
    "Sobel gray threshold Frame1\n",
    "\n",
    "![title][image4]\n",
    "\n",
    "1. I made color threhsold for white and yellow color from diffrent color space as shown in `CTHR()` in `LaneDetect.py`\n",
    "\n",
    "Color threshold\n",
    "\n",
    "![title][image5]\n",
    "\n",
    "Combined threshold\n",
    "\n",
    "![title][image6]\n",
    "\n",
    "#### 3.Perspective transform.\n",
    "The code for my perspective transform includes a function called `prespectI()`. The function takes as inputs an image (`img`), as well as the source (`src`) and destination (`dst`) points was chosen trial and error until produce the most parallel two lines.  I chose the hardcode the source and destination points in the following manner:\n",
    "\n",
    "```python\n",
    " src=np.float32([[728,475],\n",
    "                  [1058,690],\n",
    "                  [242,690],\n",
    "                  [565,475]])\n",
    "    \n",
    " dst=np.float32([[1058,20],\n",
    "                  [1058,700],\n",
    "                  [242,700],\n",
    "                  [242,20]])\n",
    "```\n",
    "This resulted `warped ` image as the following image after applying `cv2.getPerspectiveTransform(src, dst)` that return Image matrix `M` and feed it to `cv2.warpPerspective()`.\n",
    "\n",
    "![alt text] [image8]\n",
    "\n",
    "#### 4. Line fitting\n",
    "`LineFitting()` in cell `[137]`idintifys the Lane pixels by computing the histogram of half buttom the image and extract 2 high peaks. After, 9 sliding windows for each lane pixels and extract the points of each lane lane lines with a 2nd order polynomial:\n",
    "\n",
    "![alt text] [image9]\n",
    "![alt text] [image10]\n",
    "![alt text] [image11]\n",
    "\n",
    "#### 5. Curvature calculation\n",
    "The curvature was calculated by chosing the maximum y-value corresponding to the bottom of the image \n",
    "```python\n",
    "    y_eval = np.max(ploty)\n",
    "    left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0]) \n",
    "```\n",
    "\n",
    "#### 6. Final result.\n",
    "\n",
    "Result for test images.\n",
    "![alt text] [image12]\n",
    "\n",
    "---\n",
    "\n",
    "### Pipeline (video)\n",
    "\n",
    "Here's a [link to my video result](https://youtu.be/3PKT84lurqE) or download `project_output.mp4`\n",
    "\n",
    "---\n",
    "\n",
    "### Discussion\n",
    "\n",
    "The proposed solution showed high accuracy in each frame. However the system is slow due to extracting Sobel edge. Also, it need to be tuned and other segmentation techniques such as watershed can produce robuster system. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
