{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Advanced Lane Detection Report\n",
    "---\n",
    "This project aims to detect Lane lines robustly during high lighting distortion. This report reprsents software pipline and preview two diffrent frames oitput at each stage. the first frame with normal lighting condition and second frame with high lighting disruption.\n",
    "\n",
    "---\n",
    "[image1]: ./output_images/Frame2.png \"distorted1\"\n",
    "[image2]: ./output_images/Undistorted2.png \"Udistorted1\"\n",
    "[image3]: ./output_images/ROIo1.png \"ROI\"\n",
    "[image4]: ./output_images/ROIo2.png \"ROI\"\n",
    "[image5]: ./output_images/S-Sobel1.png \"S-Channel gradiant\"\n",
    "[image6]: ./output_images/S-Sobel1040.png \"S-Channel gradiant2\"\n",
    "[image7]: ./output_images/Gray_Sobel1.png \"Gray gradiant\"\n",
    "[image8]: ./output_images/Gray_Sobel1040.png \"Gray gradiant2\"\n",
    "[image9]: ./output_images/Combined_threshold1.png \"Combined gradiant\"\n",
    "[image10]: ./output_images/Combined_threshold1040.png \"Combined gradiant\"\n",
    "[image11]: ./output_images/warped_frame1.png \"Prespictive ROI\"\n",
    "[image12]: ./output_images/warped_frame1040.png \"Prespictive ROI\"\n",
    "[image13]: ./output_images/Window_Image1.png \"W_Line fit 1\"\n",
    "[image14]: ./output_images/Window_Image1040.png \"W_Line fit 2\"\n",
    "[image15]: ./output_images/Line_Image1.png \"Line fit 1\"\n",
    "[image16]: ./output_images/Line_Image1040.png \"Line fit 2\"\n",
    "[image17]: ./output_images/Un_warped1.png \"Result\"\n",
    "[image18]: ./output_images/Un_warped1040.png \"Result2\"\n",
    "#### 1. Camera calibration.\n",
    "\n",
    "The code for this step is contained in `def undistorT(imgorg)` function. I start by preparing \"object points\", which will be the (x, y, z) coordinates of the chessboard corners in the world. Here I am assuming the chessboard is fixed on the (x, y) plane at z=0, such that the object points are the same for each calibration image.  Thus, `objp` is just a replicated array of coordinates, and `objpoints` will be appended with a copy of it every time I successfully detect all chessboard corners in a test image.  `imgpoints` will be appended with the (x, y) pixel position of each of the corners in the image plane with each successful chessboard detection. I then used the output `objpoints` and `imgpoints` to compute the camera calibration and distortion coefficients using the `cv2.calibrateCamera()` function.  I applied this distortion correction to the test image using the `cv2.undistort()` function and obtained this result: \n",
    "![title][image1]\n",
    "![title][image2]\n",
    "#### 2. Image segmentation.\n",
    "I used a combination of color and gradient thresholds to generate a binary image. I made thrshold in two levels:\n",
    "\n",
    "* I computed the gradiant of extracted S-Channel from frame in respective x & y. Also, graduate magnitude was calculated and minimum threshold was applied as in the function `SobelThr(img,n)`. The ouput binary Image segmented the Lane clearly in good lighting condition but with some noise in distorted frame with high lightness.\n",
    "Sobel S-channel threshold Frame1\n",
    "![title][image5]\n",
    "Sobel S-channel threshold\n",
    "![title][image6]\n",
    "* As a result the nois is high even after applying `cv2.bilateralFilter(image,7,150,150)`. with repeat computing the gradient for the gray frame and combining the both with OR operatin in order to collect the maximum number of pixels the belong to the both lane along the lighting condition changes.\n",
    "Gradient gray frame 1\n",
    "![alt text][image7]\n",
    "Gradient gray frame 2\n",
    "![alt text][image8]\n",
    "Combined Threhsold frame 1\n",
    "![alt text][image9]\n",
    "Combined Threhsold frame 2\n",
    "![alt text][image10]\n",
    "#### 3.Perspective transform.\n",
    "The code for my perspective transform includes a function called `prespectI()`, which appears in cell `[127]`in the file `ADLane-P.ipynb`. The function takes as inputs an image (`img`), as well as the source (`src`) and destination (`dst`) points was chosen trial and error until produce the most parallel two lines.  I chose the hardcode the source and destination points in the following manner:\n",
    "\n",
    "```python\n",
    "src=np.float32([[685,450],\n",
    "                [1055,700],\n",
    "                [215,700],\n",
    "                [550,450]])\n",
    "    \n",
    "dst=np.float32([[1055,20],\n",
    "                 [1055,700],\n",
    "                 [215,700],\n",
    "                 [215,20]])\n",
    "```\n",
    "This resulted `warped ` image as the following image after applying `cv2.getPerspectiveTransform(src, dst)` that return Image matrix `M` and feed it to `cv2.warpPerspective()`.\n",
    "\n",
    "Warped frame1\n",
    "![alt text] [image11]\n",
    "Warped frame2\n",
    "![alt text] [image12]\n",
    "#### 4. Line fitting\n",
    "`LineFitting()` in cell `[137]`idintifys the Lane pixels by computing the histogram of half buttom the image and extract 2 high peaks. After, 9 sliding windows for each lane pixels and extract the points of each lane lane lines with a 2nd order polynomial kinda like this:\n",
    "\n",
    "```python\n",
    "for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = wimgun.shape[0] - (window+1)*window_height\n",
    "        win_y_high = wimgun.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, wimgun.shape[0]-1, wimgun.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "```\n",
    "\n",
    "Window Fitting frame 1\n",
    "![alt text] [image13]\n",
    "Window Fitting frame 2\n",
    "![alt text] [image14]\n",
    "Line Fitting frame 1\n",
    "![alt text] [image15]\n",
    "Line Fitting frame 2\n",
    "![alt text] [image16]\n",
    "\n",
    "#### 5. Curvature calculation\n",
    "The curvature was calculated by chosing the maximum y-value corresponding to the bottom of the image \n",
    "```python\n",
    "    y_eval = np.max(ploty)\n",
    "    left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0]) \n",
    "```\n",
    "\n",
    "#### 6. Final result.\n",
    "The following are the results after unwarping the frames in two diffrent condditions. \n",
    "Result Frame 1\n",
    "![alt text] [image17]\n",
    "Result Frame2\n",
    "![alt text] [image18]\n",
    "\n",
    "---\n",
    "\n",
    "### Pipeline (video)\n",
    "\n",
    "\n",
    "Here's a [link to my video result](./out_video.avi)\n",
    "\n",
    "---\n",
    "\n",
    "### Discussion\n",
    "\n",
    "The combination of thresholding produces good results. it fails in few frame that has high lightness distortion and detect the Lanes inbound or outbound with small deviation.The proposed work can be better by equilizing  the L-channel and apply spbel gradient on S+L. However, even after many tuning its harsh to get the code to be tuned good for all the frames. therefore averaging of pervious number of lines will bring better resutl. Also, I repeated same algorithm to idintify the windows because with rough lighting condition or any sort of noise could lead to arbitrary lines. this system can be tuned better to fit the other challenging videos. Also Tracking histogram by Camshift algortith can make better results as it calculate the center mass of the bulb color. the solution can be better however due to short time and difficulties of some project, I did the minimum requirments. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
